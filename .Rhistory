wt4<-mtcars[, mtcars$cyl==4]
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit3<-lm(y~x)
dfbeta(fit3)
hatvalues(fit3)
dfbeta(fit3[,max(hatvalues(fit3))])
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
lm(mpg ~ wt + factor(cyl), data = mtcars)
lm(mpg ~ factor(cyl), data = mtcars)
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
?influence.measure
??influence.measure
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
lm(mpg ~ factor(cyl), data = mtcars)
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
fit5<-lm(mpg ~ wt + factor(cyl), data = mtcars)
fit7<-lm(mpg ~ wt + factor(cyl)+cyl*wt, data = mtcars)
lrtest(fit5, fit7)
library(lmtest)
install.packages(lmtest)
install.packages("lmtest")
library(lmtest)
lrtest(fit5,fit7)
max(hatvalues(fit))
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
max(hatvalues(fit))
influence.measures(fit)$infmat[5, 'dfb.x']
library("swirl")
rm(list=ls())
swirl()
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent -1, galton)
lm(child ~ parent,galton)
lm(child ~ 1, galton)
head(trees)
fit <- lm(Volume ~ Girth + Height + Constant -1, trees)
trees2 <- eliminate("Girth",trees)
head(trees)
head(trees2)
fit2 <- lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit, fit2), coef)
lm(Fertility~.,data="swiss")
lm(Fertility~.,data=swiss)
all <- lm(Fertility ~ ., swiss)
summary(all)
lm(Fertility~agriculture,data=swiss)
lm(Fertility~agriculture,data=swiss)
summary(lm(Fertility~agriculture,data=swiss))
summary(lm(Fertility ~ Agriculture, data = swiss))
cor(swiss$Examination,swiss$Education)
cor(swiss$Agriculture,swiss$Education)
makelms()
ec<-swiss$Examination+swiss$Catholic
efit<-lm(Fertility ~ Agriculture + Catholic + Education + Examination +Infant.Mortality+ec, swiss)
all$coefficients-efit$coefficients
6
dim(InsectSprays)
head(InsectSprays)
head(InsectSprays,15)
xa
sa
xA
sA
summary(InsectSprays[,2])
sapply(class,InsectSprays)
sapply(class,data=InsectSprays)
?sapply
sapply(InsectSprays,class)
fit<-(count~spray,data=InsectSprays)
fit<-lm(count~spray,data=InsectSprays)
summary(fit)
summary(fit)$coef
est<-summary(fit)$coef[,1]
mean(sA)
mean(sB)
nfit<-lm(count ~ spray - 1,data=InsectSprays)
summary(nfit$coefficients)
summary(nfit)$coef
spray2<-relevel(InsectSprays$spray,C)
spray2<-relevel(InsectSprays$spray,"C")
fit2<-lm(count ~ spray - 1,data=InsectSprays)
fit2 <- lm(count ~ spray2, InsectSprays)
summary(fit2)$coef
mean(sC)
(fit$coef[2]-fit$coef[3])/1.6011
dim(hunger)
948
names(hunger)
fit<-lm(Numeric~Year)
fit<-lm(Numeric~Year,data=hunger)
summary(fit)$coef
lmf<-lm(Numeric~Year+sex[hunger$Sex=="Female"],data=hunger)
lmf<-lm(Numeric~Year,data=hunger)
lmF <-lm(Numeric[Sex=="Female"] ~ Year[Sex=="Female"],hunger)
lmM <-lm(Numeric[Sex=="Male"] ~ Year[Sex=="Male"],hunger)
lmBoth <-lm(Numeric ~ Year+Sex,hunger)
summary(lmBoth)
lmInter <-lm(Numeric ~ Year+Sex+Sex*Year,hunger)
summary(lmInter)
library(datasets)
summary(cars)
hist(cars)
head(cars)
data(mtcars)
head(mtcars)
summary(mtcars)
plot(mpg~am,data=mtcars,xlab="Transmission TYpe")
fit <- lm(mpg ~ am, data = mtcars)
summary(fit)
multi_reg_fit <- lm(mpg~am + wt + hp, data = mtcars)
summary(multi_reg_fit)
anova(fit,multi_reg_fit)
complete_reg <- lm(mpg ~ ., data=mtcars)
summary(complete_reg)
install.packages("Tex")
install.packages("pdflatex")
library(knitr)
devtools::install_github("rstudio/rmarkdown")
% ams
\usepackage{amssymb,amsmath}
+% utf8 encoding
+\usepackage[utf8]{inputenc}
+
% graphix
\usepackage{graphicx}
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
install.packages("pandoc")
install.packages("pandoc")
library(pandoc)
library(pdflatex)
install.packages("pandoc")
library(pdflatex)
install.packages("rmarkdown")
install.packages("rmarkdown")
---
title: "Coursera-Regression Assignment"
author: "Arjit"
date: "November 23, 2015"
output:
pdf_document:
keep_tex: yes
---
---
Context : I work for Motor Trend, a magazine about the automobile industry. Looking at a data set of a collection of cars, they are interested in exploring the relationship between a set of variables and miles per gallon (MPG) (outcome). They are particularly interested in the following two questions:
“Is an automatic or manual transmission better for MPG”
"Quantify the MPG difference between automatic and manual transmissions"
----
Loading dataset library  & mtcars data
```{r}
library(datasets)
data(mtcars)
head(mtcars)
```
Getting a feel of Data
```{r}
summary(mtcars)
```
Plotting some graphs
```{r, echo=TRUE}
plot(mpg~am,data=mtcars,xlab="Transmission Type")
```
Plots suggest that there is significant difference
between Transmission Type and mpg
Simple Linear Regression
````{r,echo=TRUE}
fit <- lm(mpg ~ am, data = mtcars)
summary(fit)
````
Our Null Hypothesis
H(0)= There is no difference between mpg and transmission
H(1)= There is significant difference between mpg and Transmission
Since the summary statistics suggest that at 95 % Interval
the probability is <.05 and the Confidence interval does not
include zero , we can reject the null hypothesis
Also, the adjusted R square value is .3385 , which means that we
can explain only 33.85% of regression variance using our model. We need
to use many other predictor variables to seek more details
# Multiple Regression
````{r}
multi_reg_fit <- lm(mpg~am + wt + hp, data = mtcars)
summary(multi_reg_fit)
````
regression line : mpg=34.002875+ 2.083710 am-2.878575wt-0.037479hp
# Running the Annova test compare the two models
````{r}
anova(fit,multi_reg_fit)
`````
The p Value and the adjusted R-square value suggest that our multiple
regression model is significantly different than simple linear regression
model
# Full Model Regression
`````{r}
complete_reg <- lm(mpg ~ ., data=mtcars)
summary(complete_reg)
`````
# Is an automatic or manual transmission better for MPG
Ans: Automatic transmission is better fot MPG
# Quantify the MPG difference between automatic and manual transmissions
Ans: Explained in Models above
install.packages("devtools")
library(devtools)
devtools::install_github('rstudio/rmarkdown')
install.packages("Tex")
rmarkdown::render('in.md',
output_format=pdf_document(latex_engine='xelatex')
)
?pandoc
??pandoc
install.packages("pandoc")
install.packages("pandoc")
install.packages("Pandoc")
install.package("stringi")
install.packages("stringi")
install.packages("stringi")
install.packages("Pandoc")
install.packages("MikiTex")
library(ggplot2)
library(ggplot2)
set.seed(1)
n<-40
lambda<-0.2
numsim<-1000
num_simulation<-1000
final_dat<-matrix(rexp(n*num_simulation,lambda),num_simulation)
theoritical_Mean<-1/lambda
row_Means<-apply(final_dat,1,mean)
actual_Mean<-mean(row_Means)
theory_SD<-((1/lambda) * (1/sqrt(n)))
actual_SD<-sd(row_Means)
theory_Var<-theory_SD^2
actual_Var<-var(row_Means)
data_frame<-data.frame(row_Means)
g<-ggplot(data_frame,aes(x=row_Means))
g<-mp+geom_histogram(binwidth = lambda,fill="green",color="black",aes(y = ..density..))
g<-g + labs(title="Density of 40 Numbers from Exponential Distribution", x="Mean of 40 Selections", y="Density")
g<-g + geom_vline(xintercept=actual_Mean,size=1.0, color="red")
g<-g + stat_function(fun=dnorm,args=list(mean=actual_Mean, sd=actual_SD),color = "blue", size = 1.0)
g<-g + geom_vline(xintercept=theory_Mean,size=1.0,color="yellow",linetype = "longdash")
g<-g + stat_function(fun=dnorm,args=list(mean=theory_Mean, sd=theory_SD),color = "red", size = 1.0)
g
data_frame<-data.frame(row_Means)
g<-ggplot(data_frame,aes(x=row_Means))
g<-mp+geom_histogram(binwidth = lambda,fill="green",color="black",aes(y = ..density..))
g<-g + labs(title="Density of 40 Numbers from Exponential Distribution", x="Mean of 40 Selections", y="Density")
g<-g + geom_vline(xintercept=actual_Mean,size=1.0, color="red")
g<-g + stat_function(fun=dnorm,args=list(mean=actual_Mean, sd=actual_SD),color = "blue", size = 1.0)
g<-g + geom_vline(xintercept=theoritical_Mean,size=1.0,color="yellow",linetype = "longdash")
g<-g + stat_function(fun=dnorm,args=list(mean=theoritical_Mean, sd=theory_SD),color = "red", size = 1.0)
g
data_frame<-data.frame(row_Means)
g<-ggplot(data_frame,aes(x=row_Means))
g<-g+geom_histogram(binwidth = lambda,fill="green",color="black",aes(y = ..density..))
g<-g + labs(title="Density of 40 Numbers from Exponential Distribution", x="Mean of 40 Selections", y="Density")
g<-g + geom_vline(xintercept=actual_Mean,size=1.0, color="red")
g<-g + stat_function(fun=dnorm,args=list(mean=actual_Mean, sd=actual_SD),color = "blue", size = 1.0)
g<-g + geom_vline(xintercept=theoritical_Mean,size=1.0,color="yellow",linetype = "longdash")
g<-g + stat_function(fun=dnorm,args=list(mean=theoritical_Mean, sd=theory_SD),color = "red", size = 1.0)
g
library(datasets)
library(ggplot2)
data(ToothGrowth)
dim(ToothGrowth)
head(ToothGrowth)
lapply(class,ToothGrowth)
lapply(ToothGrowth,class)
plot(dose,len,data=ToothGrowth, col=supp, main="Tooth growth of guinea pigs",xlab="Dosage (mg)", ylab="length of Tooth")
qplot(dose,len,data=ToothGrowth, col=supp, main="Tooth growth of guinea pigs",xlab="Dosage (mg)", ylab="length of Tooth")
summary(ToothGrowth)
qplot(supp,len,data=ToothGrowth, facets=~dose, main="Tooth growth of guinea pigs by supplement type and dosage (mg)",xlab="Supplement type", ylab="Tooth length") + geom_boxplot(aes(fill = supp))
len_suppOJ = ToothGrowth$len[ToothGrowth$supp == 'OJ']
len_suppVC = ToothGrowth$len[ToothGrowth$supp == 'VC']
t.test(len_suppOJ, len_suppVC, alternative = "greater", paired = FALSE, var.equal = FALSE, conf.level = 0.95)
dose_Half = ToothGrowth$len[ToothGrowth$dose == 0.5]
dose_One = ToothGrowth$len[ToothGrowth$dose == 1]
dose_Two = ToothGrowth$len[ToothGrowth$dose == 2]
# half and one
t.test(doseHalf, doseOne, alternative = "less", paired = FALSE, var.equal = FALSE, conf.level = 0.95)
# One and two
t.test(doseOne, doseTwo, alternative = "less", paired = FALSE, var.equal = FALSE, conf.level = 0.95)
t.test(dose_Half, dose_One, alternative = "less", paired = FALSE, var.equal = FALSE, conf.level = 0.95)
# One and two
t.test(dose_One, dose_Two, alternative = "less", paired = FALSE, var.equal = FALSE, conf.level = 0.95)
library(swirl)
swirl()
10/sqrt(100)
(32-30)/1
(32-30)/10/sqrt(16)
(32-30)/(10/4)
15
qt(.95,15)
dim(fs)
t.test(fs$sheight-fs$fheight)
11.7885 *sd(fs$sheight-fs$fheight)/sqrt(1078)
mybin
8
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
install.packages("ISLR")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
train = createDataPartition(diagnosis, p = 0.50,list=FALSE)
test = createDataPartition(diagnosis, p = 0.50,list=FALSE)
train
test
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
hist(SuperPlasticizer,data=training,col="green")
head(training)
qplot(SuperPlasticizer,data=training,col="green")
qplot(training$Superplasticizer,col="green")
mean(training$Superplasticizer)
sd(training$Superplasticizer)
qplot(training$Superplasticizer,geom="density")
log(-10)
training
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
M<-abs(cor(training[,-12]))
head(training)
View(training)
View(training)
M<-abs(cor(training[,-12]))
M<-abs(cor(training[,-12]))
M<-abs(cor(training[,-1]))
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.9)
preProc$rotation
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
install.packages("Hmisc")
library(Hmisc)
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
install.packages("e1071")
library(e1071)
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
## get the confustion matrix for the first method
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
A1 <- C1$overall[1]
A1
modelFit <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca",
data = training, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
A2 <- C2$overall[1]
A2
A1
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
install.packages("ElemStatLearn")
install.packages("pgmm")
library(rpart)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
head(segmentationOriginal)
train<-segmentationOriginal[,segmentationOriginal$Case=='Train']
train<-segmentationOriginal[,segmentationOriginal$Case=="Train"]
train<-segmentationOriginal[segmentationOriginal$Case=="Train",]
head(train)
test<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
modFit<-train(Case~.,method="rpart",data=train)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
modFit<-train(Case~.,method="rpart",data=training)
count(training.Case=="Test")
modFit<-train(Class~.,method="rpart",data=training)
fancyRpartPlot(modFit)
library(rattle)
install.packages("rattle")
library(rattle)
library(rattle)
fancyRpartPlot(modFit)
fancyRpartPlot(modFit)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
predData <- training[1:4,]
which(colnames(training)=="TotalIntenCh2")
which(colnames(training)=="FiberWidthCh1")
which(colnames(training)=="PerimStatusCh1")
which(colnames(training)=="VarIntenCh4")
predData
library(pgmm)
data(olive)
olive = olive[,-1]
modFit<-train(Area~.,method="rpart",data=olive)
newdata = as.data.frame(t(colMeans(olive)))
print(modFit$finalModel)
predict(modFit,newdata=newdata)
head(olive)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
colnames(train)
colnames(trainSA)
model<-train(chd~age+alchohol+obesity+tobacco+typea+ldl,method="glm", family="binomial",data=trainSA)
model<-train(chd~age+alcohol+obesity+tobacco+typea+ldl,method="glm", family="binomial",data=trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predictTrain <- predict(model, trainSA)
predictTest <- predict(model, testSA)
missClass(trainSA$chd, predictTrain)
missClass(testSA$chd, predictTest)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
modelRf <- train(y ~ ., data = vowel.train, method="rf",prox=TRUE)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
library(shiny)
runExample("01_hello")
runExample("01_hello")
runApp("C:/Users/Nemes!s/Documents/GitHub/Shiny Test")
runApp("C:/Users/Nemes!s/Documents/GitHub/Shiny Test")
runApp("C:/Users/Nemes!s/Documents/GitHub/Shiny Test",display.mode = "showcase")
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
library(shiny)
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
shiny::runApp('GitHub/Shiny Test')
install.packages(c("maps", "mapproj"))
setwd("C:/Users/Nemes!s/Documents/GitHub/Shiny Test/data")
counties <- readRDS("census-app/data/counties.rds")
head(counties)
counties <- readRDS("census-app/data/counties.rds")
setwd("C:/Users/Nemes!s/Documents/GitHub/Shiny Test")
counties <- readRDS("census-app/data/counties.rds")
counties <- readRDS("census-app/data/counties.rds")
library(maps)
library(mapproj)
source("census-app/helpers.R")
counties <- readRDS("census-app/data/counties.rds")
percent_map(counties$white, "darkgreen", "% white")
library(maps)
library(mapproj)
source("census-app/data/helpers.R")
counties <- readRDS("census-app/data/counties.rds")
percent_map(counties$white, "darkgreen", "% white")
shiny::runApp()
shiny::runApp()
setwd("C:/Users/Nemes!s/Documents/GitHub/DataProducts")
shiny::runApp()
shiny::runApp()
shiny::runApp()
